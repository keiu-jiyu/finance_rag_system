from typing import Dict, List, Tuple
from .vector_db import get_vector_db
from .bm25_retriever import get_bm25_retriever
from .llm_service import get_llm_service
import os
from dotenv import load_dotenv

load_dotenv()

class RAGRetriever:
    def __init__(self):
        self.vector_db = get_vector_db()
        self.bm25 = get_bm25_retriever()
        self.llm = get_llm_service()
        
        # é˜ˆå€¼é…ç½®
        self.query_threshold = float(os.getenv("QUERY_THRESHOLD", 0.90))
        self.qa_threshold = float(os.getenv("QA_THRESHOLD", 0.75))
        self.doc_threshold = float(os.getenv("DOC_THRESHOLD", 0.70))
    
    def retrieve(self, query: str, top_k: int = 5) -> Dict:
        """äº”å±‚çº§è”æ£€ç´¢"""
        
        print(f"\nğŸ” å¼€å§‹æ£€ç´¢: {query}")
        
        # ç¬¬1å±‚ï¼šQueryåº“æ£€ç´¢
        print("ğŸ“ ã€ç¬¬1å±‚ã€‘Queryåº“æ£€ç´¢...")
        query_results = self.vector_db.search_query(
            query, top_k, self.query_threshold
        )
        
        if query_results and query_results[0]['similarity'] > self.query_threshold:
            print(f"âœ… ã€ç¬¬1å±‚ã€‘å‘½ä¸­! ç›¸ä¼¼åº¦: {query_results[0]['similarity']:.4f}")
            return {
                'layer': 1,
                'type': 'query',
                'result': query_results[0]['metadata'].get('answer', ''),
                'source': 'Queryåº“',
                'confidence': query_results[0]['similarity']
            }
        
        # ç¬¬2å±‚ï¼šQAåº“æ£€ç´¢
        print("ğŸ“ ã€ç¬¬2å±‚ã€‘QAåº“æ£€ç´¢...")
        qa_results = self.vector_db.search_qa(
            query, top_k, self.qa_threshold
        )
        
        if qa_results:
            print(f"âœ… ã€ç¬¬2å±‚ã€‘å‘½ä¸­! ç›¸ä¼¼åº¦: {qa_results[0]['similarity']:.4f}")
            
            qa_contexts = [
                f"Q: {r['metadata'].get('question', '')}\nA: {r['metadata'].get('answer', '')}"
                for r in qa_results[:top_k]
            ]
            
            answer = self.llm.generate_with_context(query, qa_contexts)
            
            return {
                'layer': 2,
                'type': 'qa',
                'result': answer,
                'source': 'QAåº“ + LLM',
                'confidence': qa_results[0]['similarity'],
                'contexts': qa_contexts
            }
        
        # ç¬¬3å±‚ï¼šDocåº“æ£€ç´¢
        print("ğŸ“ ã€ç¬¬3å±‚ã€‘Docåº“æ£€ç´¢...")
        doc_results = self.vector_db.search_docs(
            query, top_k, self.doc_threshold
        )
        
        if doc_results:
            print(f"âœ… ã€ç¬¬3å±‚ã€‘å‘½ä¸­! ç›¸ä¼¼åº¦: {doc_results[0]['similarity']:.4f}")
            
            doc_contexts = [r['text'] for r in doc_results[:top_k]]
            answer = self.llm.generate_with_context(query, doc_contexts)
            
            return {
                'layer': 3,
                'type': 'docs',
                'result': answer,
                'source': 'Docåº“ + LLM',
                'confidence': doc_results[0]['similarity'],
                'contexts': doc_contexts
            }
        
        # ç¬¬4å±‚ï¼šBM25æ··åˆæ£€ç´¢
        print("ğŸ“ ã€ç¬¬4å±‚ã€‘BM25æ··åˆæ£€ç´¢...")
        bm25_results = self.bm25.search(query, top_k)
        
        if bm25_results:
            print(f"âœ… ã€ç¬¬4å±‚ã€‘å‘½ä¸­! å¾—åˆ†: {bm25_results[0]['score']:.4f}")
            
            bm25_contexts = [r['text'] for r in bm25_results[:top_k]]
            answer = self.llm.generate_with_context(query, bm25_contexts)
            
            return {
                'layer': 4,
                'type': 'bm25',
                'result': answer,
                'source': 'BM25 + LLM',
                'confidence': min(bm25_results[0]['score'] / 100, 0.9),
                'contexts': bm25_contexts
            }
        
        # ç¬¬5å±‚ï¼šè‡ªç”±ç”Ÿæˆ
        print("ğŸ“ ã€ç¬¬5å±‚ã€‘è‡ªç”±ç”Ÿæˆ...")
        
        free_prompt = f"""ç”¨æˆ·é—®é¢˜: {query}

è¯·åŸºäºä½ çš„çŸ¥è¯†è¿›è¡Œå›ç­”ã€‚å¦‚æœä½ ä¸ç¡®å®šç­”æ¡ˆï¼Œè¯·å‘Šè¯‰ç”¨æˆ·ã€‚"""
        
        answer = self.llm.generate(free_prompt)
        
        return {
            'layer': 5,
            'type': 'free',
            'result': answer,
            'source': 'è‡ªç”±ç”Ÿæˆ',
            'confidence': 0.5
        }


# å…¨å±€å®ä¾‹
_retriever = None

def get_retriever():
    global _retriever
    if _retriever is None:
        _retriever = RAGRetriever()
    return _retriever