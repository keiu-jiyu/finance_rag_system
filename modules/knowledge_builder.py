import os
import json
from typing import List
import PyPDF2
import jieba
from .vector_db import get_vector_db
from .bm25_retriever import get_bm25_retriever

class KnowledgeBuilder:
    def __init__(self):
        self.vector_db = get_vector_db()
        self.bm25 = get_bm25_retriever()
    
    def process_pdf(self, file_path: str, kb_type: str = 'docs') -> int:
        """å¤„ç†PDFæ–‡ä»¶"""
        print(f"ğŸ“„ å¤„ç†PDF: {file_path}")
        
        count = 0
        try:
            with open(file_path, 'rb') as f:
                reader = PyPDF2.PdfReader(f)
                
                for page_num, page in enumerate(reader.pages):
                    text = page.extract_text()
                    
                    # åˆ†æ®µå¤„ç†
                    for segment in self._chunk_text(text):
                        if kb_type == 'docs':
                            self.vector_db.add_doc_document(
                                segment,
                                source=os.path.basename(file_path)
                            )
                        
                        count += 1
        
        except Exception as e:
            print(f"âŒ PDFå¤„ç†å¤±è´¥: {str(e)}")
        
        print(f"âœ… å·²å¤„ç†{count}ä¸ªæ–‡æœ¬æ®µ")
        return count
    
    def process_txt(self, file_path: str, kb_type: str = 'docs') -> int:
        """å¤„ç†TXTæ–‡ä»¶"""
        print(f"ğŸ“ å¤„ç†TXT: {file_path}")
        
        count = 0
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()
                
                for segment in self._chunk_text(text):
                    if kb_type == 'docs':
                        self.vector_db.add_doc_document(
                            segment,
                            source=os.path.basename(file_path)
                        )
                    
                    count += 1
        
        except Exception as e:
            print(f"âŒ TXTå¤„ç†å¤±è´¥: {str(e)}")
        
        print(f"âœ… å·²å¤„ç†{count}ä¸ªæ–‡æœ¬æ®µ")
        return count
    
    def process_json(self, file_path: str) -> int:
        """å¤„ç†JSONæ ¼å¼çš„QAæ•°æ®"""
        print(f"ğŸ“‹ å¤„ç†JSON: {file_path}")
        
        count = 0
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                # æ”¯æŒä¸¤ç§æ ¼å¼
                if isinstance(data, list):
                    items = data
                else:
                    items = data.get('data', [])
                
                for item in items:
                    if 'question' in item and 'answer' in item:
                        self.vector_db.add_qa_document(
                            item['question'],
                            item['answer']
                        )
                        count += 1
                    elif 'query' in item and 'answer' in item:
                        # é«˜è´¨é‡query-answerå¯¹
                        self.vector_db.add_query_document(
                            item['query'],
                            item['answer']
                        )
                        count += 1
        
        except Exception as e:
            print(f"âŒ JSONå¤„ç†å¤±è´¥: {str(e)}")
        
        print(f"âœ… å·²å¤„ç†{count}ä¸ªQAå¯¹")
        return count
    
    @staticmethod
    def _chunk_text(text: str, chunk_size: int = 500,
                   overlap: int = 50) -> List[str]:
        """æ–‡æœ¬åˆ†å—"""
        chunks = []
        
        for i in range(0, len(text), chunk_size - overlap):
            chunk = text[i:i + chunk_size]
            if chunk.strip():
                chunks.append(chunk)
        
        return chunks
    
    def persist(self):
        """ä¿å­˜çŸ¥è¯†åº“"""
        self.vector_db.persist()
        print("âœ… çŸ¥è¯†åº“å·²ä¿å­˜")